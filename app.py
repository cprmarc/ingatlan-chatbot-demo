import subprocess
import sys

# Automatikus modultelepÃ­tÃ©s, ha hiÃ¡nyzik
def ensure_package_installed(package_name, import_name=None):
    try:
        __import__(import_name or package_name)
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])
        print(f"{package_name} telepÃ­tve.")

# SzÃ¼ksÃ©ges csomagok ellenÅ‘rzÃ©se Ã©s telepÃ­tÃ©se
ensure_package_installed("langchain-openai", "langchain_openai")
ensure_package_installed("openai")
ensure_package_installed("langchain")
ensure_package_installed("langchain-community")
ensure_package_installed("faiss-cpu")
ensure_package_installed("streamlit")
ensure_package_installed("requests")
ensure_package_installed("beautifulsoup4")
ensure_package_installed("tiktoken")

# ImportÃ¡lÃ¡sok
import os
import streamlit as st
from langchain_community.document_loaders import WebBaseLoader
from langchain.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Streamlit beÃ¡llÃ­tÃ¡sok
st.set_page_config(page_title="Ingatlan Chatbot", page_icon="ğŸ ")
st.title("ğŸ  Ingatlan Chatbot â€“ Webes TudÃ¡sbÃ¡zissal")

st.markdown("""
Ez a chatbot kÃ©pes vÃ¡laszolni az Ã¡ltalad megadott ingatlanos tÃ©mÃ¡jÃº weboldalak tartalma alapjÃ¡n.  
Add meg a weboldal(ak) URL-jÃ©t, Ã©s kÃ©rdezz bÃ¡rmit!
""")

# URL-ek bekÃ©rÃ©se
url_list = st.text_area("ğŸ”— Ãrd be az URL(eke)t, soronkÃ©nt egyet (pl. https://...):")

# KÃ©rdÃ©s bekÃ©rÃ©se
user_question = st.text_input("â“ KÃ©rdÃ©sed a megadott oldalakkal kapcsolatban:")

# FuttatÃ¡s gombra
if st.button("ğŸ’¬ VÃ¡lasz kÃ©rÃ©se") and url_list and user_question:
    with st.spinner("ğŸ”„ BetÃ¶ltÃ©s Ã©s feldolgozÃ¡s..."):
        try:
            # Weboldalak betÃ¶ltÃ©se
            urls = url_list.strip().split("\n")
            loader = WebBaseLoader(urls)
            documents = loader.load()

            # DokumentumdarabolÃ¡s
            splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            docs = splitter.split_documents(documents)

            # Embedding + FAISS index
            embeddings = OpenAIEmbeddings()
            vectorstore = FAISS.from_documents(docs, embeddings)

            # KÃ©rdÃ©s-vÃ¡lasz lÃ¡nc
            retriever = vectorstore.as_retriever()
            qa_chain = RetrievalQA.from_chain_type(
                llm=ChatOpenAI(temperature=0),
                retriever=retriever,
                return_source_documents=True
            )

            result = qa_chain(user_question)

            st.subheader("ğŸ’¡ VÃ¡lasz:")
            st.write(result['result'])

            st.subheader("ğŸ“š ForrÃ¡s(ok):")
            for doc in result["source_documents"]:
                st.markdown(f"- [{doc.metadata['source']}]({doc.metadata['source']})")
        
        except Exception as e:
            st.error(f"Hiba tÃ¶rtÃ©nt: {str(e)}")
