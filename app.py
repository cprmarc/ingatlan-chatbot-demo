import subprocess
import sys

# Automatikus modultelepÃ­tÃ©s
def ensure_package_installed(package_name, import_name=None):
    try:
        __import__(import_name or package_name)
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])
        print(f"{package_name} telepÃ­tve.")

# Csomagok biztosÃ­tÃ¡sa
ensure_package_installed("langchain-openai", "langchain_openai")
ensure_package_installed("openai")
ensure_package_installed("langchain")
ensure_package_installed("langchain-community")
ensure_package_installed("faiss-cpu")
ensure_package_installed("streamlit")
ensure_package_installed("requests")
ensure_package_installed("beautifulsoup4")
ensure_package_installed("tiktoken")

# ImportÃ¡lÃ¡s
import streamlit as st
from langchain_community.document_loaders import WebBaseLoader
from langchain.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ğŸ”— BeÃ©getett weboldalak (ide Ã­rd be az URL-eket, amikbÅ‘l dolgozzon)
PREDEFINED_URLS = [
    "https://www.ingatlan.com/blog/lakasvasarlas-tippek",
    "https://www.ingatlan.com/blog/energetikai-tanusitvany",
    "https://www.ingatlan.com/blog/hitelkalkulator-mukodese"
    # â• Ide jÃ¶hetnek tovÃ¡bbi oldalak
]

# Streamlit UI
st.set_page_config(page_title="Ingatlan Chatbot", page_icon="ğŸ ")
st.title("ğŸ  Ingatlan Chatbot â€“ TudÃ¡sbÃ¡zis WeboldalakrÃ³l")

st.markdown("KÃ©rdezz bÃ¡tran! A vÃ¡laszokat a hÃ¡ttÃ©rben beÃ¡llÃ­tott szakmai weboldalak alapjÃ¡n kapod meg.")

# KÃ©rdÃ©s bekÃ©rÃ©se
user_question = st.text_input("â“ Ãrd be a kÃ©rdÃ©sed az ingatlanokkal kapcsolatban:")

# VÃ¡laszgenerÃ¡lÃ¡s
if st.button("ğŸ’¬ VÃ¡lasz kÃ©rÃ©se") and user_question:
    with st.spinner("ğŸ”„ TudÃ¡sbÃ¡zis betÃ¶ltÃ©se Ã©s vÃ¡lasz kÃ©szÃ­tÃ©se..."):
        try:
            loader = WebBaseLoader(PREDEFINED_URLS)
            documents = loader.load()

            splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            docs = splitter.split_documents(documents)

            embeddings = OpenAIEmbeddings()
            vectorstore = FAISS.from_documents(docs, embeddings)

            retriever = vectorstore.as_retriever()
            qa_chain = RetrievalQA.from_chain_type(
                llm=ChatOpenAI(temperature=0),
                retriever=retriever,
                return_source_documents=True
            )

            result = qa_chain(user_question)

            st.subheader("ğŸ’¡ VÃ¡lasz:")
            st.write(result['result'])

            st.subheader("ğŸ“š ForrÃ¡s(ok):")
            for doc in result["source_documents"]:
                st.markdown(f"- [{doc.metadata['source']}]({doc.metadata['source']})")

        except Exception as e:
            st.error(f"Hiba tÃ¶rtÃ©nt: {str(e)}")
